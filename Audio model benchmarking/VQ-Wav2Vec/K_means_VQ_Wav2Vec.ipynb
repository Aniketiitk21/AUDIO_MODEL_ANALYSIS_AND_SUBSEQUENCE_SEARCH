{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnMmC-qXEbjO",
        "outputId": "074394f3-36ae-4341-b3b7-846ad7de8fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyrubberband\n",
            "  Downloading pyrubberband-0.3.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyrubberband) (1.16.0)\n",
            "Collecting pysoundfile>=0.8.0 (from pyrubberband)\n",
            "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from pysoundfile>=0.8.0->pyrubberband) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->pysoundfile>=0.8.0->pyrubberband) (2.21)\n",
            "Building wheels for collected packages: pyrubberband\n",
            "  Building wheel for pyrubberband (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrubberband: filename=pyrubberband-0.3.0-py3-none-any.whl size=4264 sha256=5f243b91968bfaae3569b42639f61440f513950f33a6f56ac177934f02e2c65f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/2d/f0/bb68fbfe67a42c858a79412321d28589218cbfe114c48ce664\n",
            "Successfully built pyrubberband\n",
            "Installing collected packages: pysoundfile, pyrubberband\n",
            "Successfully installed pyrubberband-0.3.0 pysoundfile-0.9.0.post1\n",
            "Collecting torch-time-stretch\n",
            "  Downloading torch_time_stretch-1.0.3-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-time-stretch) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-time-stretch) (2.2.1+cu121)\n",
            "Collecting primePy>=1.3 (from torch-time-stretch)\n",
            "  Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-time-stretch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->torch-time-stretch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->torch-time-stretch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->torch-time-stretch) (1.3.0)\n",
            "Installing collected packages: primePy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-time-stretch\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 primePy-1.3 torch-time-stretch-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyrubberband\n",
        "!pip install torch-time-stretch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from scipy import signal\n",
        "import pyrubberband as pyrb\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from torch_time_stretch import time_stretch\n",
        "import numpy as np\n",
        "# import shutil\n",
        "import tempfile\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "\n",
        "def read_audio(filepath, fs=16000,  mono=True, normalize=False, preemphasis=False):\n",
        "    \"\"\"\n",
        "    Reads audio file stored at <filepath>\n",
        "    Parameters:\n",
        "        filepath (str): audio file path\n",
        "        fs (int, optional): samping rate\n",
        "        mono (boolean, optional): return single channel\n",
        "        normalize(boolean, optional): peak normalization of signal\n",
        "        preemphasis (boolean, optional): apply pre-emphasis filter\n",
        "    Returns:\n",
        "        waveform (tensor): audio signal, dim(N,)\n",
        "    \"\"\"\n",
        "    assert isinstance(filepath, str), \"filepath must be specified as string\"\n",
        "    assert os.path.exists(filepath), f\"{filepath} does not exist.\"\n",
        "\n",
        "    try:\n",
        "        waveform, sr = torchaudio.load(filepath)\n",
        "        # mono channel\n",
        "        if waveform.shape[0] == 2 and mono is True: waveform = waveform[0]\n",
        "        else: waveform = waveform.reshape(-1)\n",
        "        # preemphasis\n",
        "        if preemphasis:\n",
        "            waveform = pre_emphasis(waveform)\n",
        "        # resample\n",
        "        if sr != fs:\n",
        "            resampler = T.Resample(sr, fs, dtype=waveform.dtype)\n",
        "            waveform = resampler(waveform)\n",
        "        # normalize\n",
        "        if normalize:\n",
        "            waveform = rms_normalize(waveform)\n",
        "        return waveform\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "\n",
        "def peak_normalize(waveform):\n",
        "    \"\"\"\n",
        "    Peak normalizes the <waveform>\n",
        "    Parameter:\n",
        "        waveform (tensor): waveform, dims: (N,)\n",
        "    \"\"\"\n",
        "    return waveform/torch.max(torch.abs(waveform))\n",
        "\n",
        "\n",
        "def rms_normalize(waveform, r=-10):\n",
        "    \"\"\"\n",
        "    RMS-normalization of  <waveform>\n",
        "    Parameter:\n",
        "        waveform (tensor): waveform, dims: (N,)\n",
        "        rms (float): rms in dB\n",
        "    \"\"\"\n",
        "    current_rms = torch.pow(torch.mean(torch.pow(waveform,2)) ,0.5)\n",
        "    scaling_factor = (10**(r/10))/current_rms\n",
        "    return waveform*scaling_factor\n",
        "\n",
        "\n",
        "def pre_emphasis(waveform, coeff=0.97):\n",
        "    filtered_sig = torch.empty_like(waveform)\n",
        "    filtered_sig[1:] = waveform[1:] - coeff*waveform[:-1]\n",
        "    filtered_sig[0] = waveform[0]\n",
        "    return filtered_sig\n",
        "\n",
        "\n",
        "def add_time_stretch(audio, fs, stretch_rate):\n",
        "    \"\"\"\n",
        "    Adds time stretch to <clean> audio by <stretch_rate> factor.\n",
        "    Parameters:\n",
        "        audio (tensor): waveform, dims: (N,)\n",
        "        fs (float): audio sample rate\n",
        "        stretch_rate (float): playback rate\n",
        "    Returns:\n",
        "        audio_stretch (tensor): time stretched waveform dims: (N*<stretch_rate>,)\n",
        "\n",
        "    \"\"\"\n",
        "    audio_stretch = time_stretch(audio.unsqueeze(0).unsqueeze(0), 1/stretch_rate, fs)\n",
        "    # assert len(audio)/stretch_rate == len(audio_stretch), f\"stretched audio length mismatch. Expected {len(audio)*stretch_rate}, got {len(audio_stretch)}\"\n",
        "    return audio_stretch.squeeze_()\n",
        "\n",
        "\n",
        "def add_pitch_shift_rb(y, sr, shift, tmpdir=None):\n",
        "    \"\"\"\n",
        "    Adds pitch shift to <y> audio sampled at <sr> by <shift> semitones. It calls rubberband package directly; does not use pyrubberband package.\n",
        "    \"\"\"\n",
        "    if isinstance(y, np.ndarray) is False:\n",
        "        y = y.numpy()\n",
        "\n",
        "    if tmpdir is not None:\n",
        "        tempfile.tempdir = tmpdir\n",
        "\n",
        "    # Get the input and output tempfile\n",
        "    fd, infile = tempfile.mkstemp(suffix='.wav')\n",
        "    os.close(fd)\n",
        "    fd, outfile = tempfile.mkstemp(suffix='.wav')\n",
        "    os.close(fd)\n",
        "\n",
        "    sf.write(infile, y, sr)\n",
        "    command = [\"rubberband\", \"-q\", \"--pitch\", str(shift), infile, outfile]\n",
        "    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    y_out, _ = sf.read(outfile, always_2d=True, dtype=y.dtype)\n",
        "    if y.ndim == 1:\n",
        "        y_out = np.squeeze(y_out)\n",
        "\n",
        "    os.unlink(infile)\n",
        "    os.unlink(outfile)\n",
        "    return torch.from_numpy(y_out).type(torch.float32)\n",
        "\n",
        "\n",
        "def add_pitch_shift(audio, fs, semitone_shift, use_rb=True):\n",
        "    \"\"\"\n",
        "    Adds pitch shift to <clean> audio by <semitone_shit> semitones.\n",
        "    Parameters:\n",
        "        audio (tensor): clean waveform, dims: (N,)\n",
        "        fs (float): audio sample rate\n",
        "        semitone_shift (float): semitones (can be between -12 and 12, but keep it low for good sound quality)\n",
        "    Returns:\n",
        "        audio_shift: pitch shifted added signal (tensor), dims: (N,)\n",
        "\n",
        "    \"\"\"\n",
        "    if use_rb:\n",
        "        audio_shift = pyrb.pitch_shift(audio.numpy(), fs, semitone_shift)\n",
        "        return torch.from_numpy(audio_shift).type(torch.float32)\n",
        "    else:\n",
        "        audio_shift = torchaudio.functional.pitch_shift(audio, fs, semitone_shift)\n",
        "        return audio_shift\n",
        "\n",
        "def add_noise(audio, noise, snr):\n",
        "    \"\"\"\n",
        "    Adds background <noise> to <clean> signal at desired <SNR> level\n",
        "    Parameters:\n",
        "        audio (tensor): clean waveform, dims: (N,)\n",
        "        noise (tensor): noise waveform, dims: (M,)\n",
        "        snr (int): SNR level in dB\n",
        "    Returns:\n",
        "        noisy_audio: noisy signal (tensor), dims: (N,)\n",
        "    \"\"\"\n",
        "    # make equal lengths for clean and noise signals\n",
        "    if len(audio) >= len(noise):\n",
        "        reps = torch.ceil(torch.tensor(len(audio)/len(noise))).int()\n",
        "        noise = torch.tile(noise, (reps,))[:len(audio)]\n",
        "    else:\n",
        "        start_idx = torch.randint(len(noise) - len(audio), (1,))\n",
        "        noise = noise[start_idx:start_idx+len(audio)]\n",
        "\n",
        "    assert len(noise) == len(audio), f\"noise signal {len(noise)} and clean signal {len(audio)} length mismatch\"\n",
        "\n",
        "    # add noise at desired snr\n",
        "    audio_rms = torch.mean(torch.pow(audio, 2))\n",
        "    noise_rms = torch.mean(torch.pow(noise, 2))\n",
        "    factor = torch.pow((audio_rms/noise_rms)/torch.pow(torch.tensor(10), (snr/10)), 0.5)\n",
        "    noise = factor*noise\n",
        "    noisy_audio = audio + noise\n",
        "    assert 10*torch.log10(audio_rms/torch.mean(torch.pow(noise, 2))) - snr < 1e-4, f\"snr mismatch {10*torch.log10(audio_rms/torch.mean(torch.pow(noise, 2))), snr, len(audio), len(noise), audio_rms, torch.mean(torch.pow(noise, 2)), noise_rms, factor, audio, torch.count_nonzero(audio)}\"\n",
        "    return noisy_audio\n",
        "\n",
        "\n",
        "def add_reverb(clean, rir):\n",
        "    \"\"\"\n",
        "    Filters <clean> signal with <rir> to get reverberation effect\n",
        "    Parameters:\n",
        "        clean (tensor): clean waveform, dims: (N,)\n",
        "        rir (tensor): room impulse response, dims: (M,)\n",
        "    Returns:\n",
        "        reverb added signal (tensor), dims: (N,)\n",
        "    \"\"\"\n",
        "    clean = clean.numpy()\n",
        "    rir = rir.numpy()\n",
        "    rir = rir/np.linalg.norm(rir)\n",
        "    # filering\n",
        "    p_max = np.argmax(np.abs(rir))\n",
        "    filtered_clean = signal.convolve(clean, rir, mode=\"full\")\n",
        "\n",
        "    # time offset\n",
        "    e = np.empty_like(filtered_clean, dtype=np.float32)\n",
        "    e[-p_max:] = 0.0\n",
        "    e[:-p_max] = filtered_clean[p_max:]\n",
        "    # filtered_clean = e.copy()\n",
        "    # e=None\n",
        "    filtered_clean = e[:len(clean)]\n",
        "    assert(len(filtered_clean)==len(clean))\n",
        "    filtered_clean = torch.from_numpy(filtered_clean)\n",
        "    return filtered_clean\n",
        "\n",
        "\n",
        "def add_noise_reverb(audio, noise, snr, rir):\n",
        "    \"\"\"\n",
        "    Adds background <noise> at desired <snr> level and reveberation using <rir> to <clean> signal\n",
        "    Parameters:\n",
        "        audio (tensor): clean waveform, dims: (N,)\n",
        "        noise (tensor): noise waveform, dims: (M,)\n",
        "        snr (int): SNR level in dB\n",
        "        rir (tensor): room impulse response, dims: (M,)\n",
        "    Returns:\n",
        "        noise and reverb added signal (tensor), dims: (N,)\n",
        "    \"\"\"\n",
        "    audio_reverb = add_reverb(audio, rir)\n",
        "    noise_reverb = add_reverb(noise, rir)\n",
        "    noise_reverb_clean = add_noise(audio_reverb, noise_reverb, snr)\n",
        "    return noise_reverb_clean"
      ],
      "metadata": {
        "id": "k5IiFX7QEe25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "librispeech_test = torchaudio.datasets.LIBRISPEECH(\".\", url=\"test-clean\", download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O81UD6zaEhHZ",
        "outputId": "d2110840-ac06-41b5-9e0c-f58c7e580428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 331M/331M [00:21<00:00, 16.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJWjYweLEj0j",
        "outputId": "5f6672a0-5717-4b69-931b-a89f70d63cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.9)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.2)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.25.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.10.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq) (12.4.99)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291765 sha256=179057719a86d77c362fc899fa58d7867fdc3ebf6d2544bd48bd7bc0817c50d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=cee03e54a3b8373369dc9ca6aebd4ae94af52d07228f1c7644417753617c553e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "UaBkYeMBGWEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import fairseq\n",
        "import torchaudio\n",
        "import os\n",
        "\n",
        "# Load pre-trained model on CPU\n",
        "cp = torch.load('/content/vq-wav2vec_kmeans.pt', map_location=torch.device('cpu'))\n",
        "model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([cp])\n",
        "model = model[0]\n",
        "model.eval()\n",
        "\n",
        "# Define the path to the audio file\n",
        "audio_file_path = '/content/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac'\n",
        "\n",
        "# Read and preprocess audio\n",
        "wav_input_16khz = read_audio(audio_file_path, fs=16000, mono=True, normalize=False, preemphasis=False)\n",
        "\n",
        "# Pass the preprocessed audio through the model\n",
        "z = model.feature_extractor(wav_input_16khz)\n",
        "_, idxs = model.vector_quantizer.forward_idx(z)\n",
        "print(idxs.shape)  # Output: torch.Size([1, 60, 2]), 60 timesteps with 2 indexes corresponding to 2 groups in the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "6S4kjv8nFBpn",
        "outputId": "8284b330-8289-49fa-c934-e70ba8029d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "unexpected EOF, expected 4236767 more bytes. The file might be corrupted.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6a5fe71ad9af>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load pre-trained model on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/vq-wav2vec_kmeans.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_ensemble_and_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         typed_storage._untyped_storage._set_from_file(\n\u001b[0m\u001b[1;32m   1277\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             torch._utils._element_size(typed_storage.dtype))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF, expected 4236767 more bytes. The file might be corrupted."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mU-9OKWYFso_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}